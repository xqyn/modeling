{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vLUQpgdAyJnq"
   },
   "source": [
    "## General instructions\n",
    "\n",
    "Please fill out the answers to the questions below in text blocks and coding blocks, as appropriate for each question. For some programming questions, some hints have already been provided for you. Add additional blocks if you need them (e.g. to explain your answers). Try to answer each question succinctly. Submit the completed notebook after filling in all the questions and please make sure that the answers are visible without needing to execute each code block (i.e. so the code block has already been executed). \n",
    "\n",
    "## Part 1: Basic Algebra and Matrices\n",
    "\n",
    "### Task 1.1 (2 points)\n",
    "\n",
    "Suppose that you are given a data matrix (X) that summarises the expenditure of 10 different hospitals across a 6 month period, where the the hospitals are stored one per row and the months are stored one per column. Write down a vector that you can multiply this matrix with to yield the following quantities. In other words, write down the vector v that causes the matrix-vector product **X * v** to yield the following:\n",
    "\n",
    "1. The average expenditure across hospitals for the whole 6 month period\n",
    "3. The difference in the total expenditure between the first three and the last three months "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nC0Wd_jWyJnr"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "X = np.random.rand(10,6) # dummy data\n",
    "print(X)\n",
    "v1 =  \n",
    "v2 = \n",
    "np.dot(X,v1.T)\n",
    "np.dot(X,v2.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gwqxZOEByJns"
   },
   "source": [
    "### Task 1.2 (1 point)\n",
    "\n",
    "Write a short piece of code that uses an eigendecomposition to determine the rank of the following matrix. Check your answer by computing the rank directly using the function np.linalg.matrix_rank():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kaa4fBnsyJns"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "X = np.array([[ 2.,  9.,  7.,  9., 11.],\n",
    "              [ 9.,  9.,  7.,  7., 11.],\n",
    "              [ 7.,  4.,  7.,  9.,  1.],\n",
    "              [ 8.,  2.,  9.,  4., -5.],\n",
    "              [ 4.,  1.,  8.,  8., -6.],\n",
    "              [ 6.,  7., 10.,  4.,  4.]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VvlxipudyJns"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a8sxUVXiyJns"
   },
   "source": [
    "### Task 1.3 (2 points)\n",
    "\n",
    "Give brief answers to the following questions: \n",
    "\n",
    "1. What is the 'curse of dimensionality and why does it pose a problem for big data analytics? \n",
    "2. When would you expect the curse of dimensionality to come into play? 'large n', 'large p' or 'large n and large p'? Explain your answer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3wX2epIEyJns"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QIatJnjQyJns"
   },
   "source": [
    "## Part 2: Machine learning and statistics\n",
    "\n",
    "### Task 2.1 (1 point)\n",
    "\n",
    "Explain the procedure you would undertake to use cross-validation to optimise the parameters of a machine learning model (e.g. the regularisation parameter in a penalised linear model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "muZv-1VsyJns"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cNy2-Yl6yJnt"
   },
   "source": [
    "### Task 2.2 (1 point)\n",
    "\n",
    "Suppose that you are a manager of a large health service aiming to test 100,000 people in your area for the SARS-CoV-2 virus. You can assume that the prevalence in the population is 1% and we will ignore transmission of the virus for this exercise (i.e. we will assume that the prevalence is fixed).  The first-generation nasal swab test has a sensitivity of approximately 75% and a specificity of 99.5%.  An alternative antibody test is available that has greatly improved sensitivity (85%) and only slightly worse specificity (97.5%).\n",
    "First, write a small block of python code to estimate the accuracy of the test under the scenarios above. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5KEE2avqyJnt"
   },
   "outputs": [],
   "source": [
    "N = 100000      # total number in the population\n",
    "num_pos =       # number of positive cases\n",
    "num_neg =       # number of negative cases\n",
    "\n",
    "# first scenario\n",
    "sens = \n",
    "spec = \n",
    "\n",
    "tp = \n",
    "tn = \n",
    "accuracy = \n",
    "print('scenario 1 =', accuracy)\n",
    "\n",
    "# second scenario\n",
    "sens = \n",
    "spec = \n",
    "\n",
    "tp = \n",
    "tn = \n",
    "acc = \n",
    "print('scenario 2 =', accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rgSUSAPwyJnt"
   },
   "source": [
    "### Task 2.3 (1 point)\n",
    "\n",
    "Which of the tests would you prefer? Give reasons for your answer. Can you think of factors that would change your preference? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i_M7J4tqyJnt"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JpAfhPyVyJnt"
   },
   "source": [
    "### Task 2.4 (1 point)\n",
    "\n",
    "What is the relationship between sample size, effect size and statistical power? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zFdbYHzAyJn5"
   },
   "source": [
    "### Task 2.5 (2 points)\n",
    "\n",
    "Matrix decomposition techniques are important ways to reduce dimensionality in big data cohorts. Provide brief answers to the following questions: \n",
    "\n",
    "1. Explain how an eigendecomposition can be used to perform principal components analysis (PCA). What do the eigenvectors and eigenvalues represent in this context? \n",
    "2. Explain how linked independent component analysis works to integrate multi-modal data. What do the components reflect? How are the components different from just concatenating the data and running PCA?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P6KSz0ouyJn5"
   },
   "source": [
    "## Part 3: Analysis of Parkinson's disease dataset\n",
    "\n",
    "For this part of the assignment, we will work with electronic measurements of voice characteristics from 42 people with early-stage Parkinson's disease. These participants were included in a six-month trial of a telemonitoring device for remote symptom progression monitoring. The motivation is that Parkinson's disease affects the characteristics of the voice in a way that might be associated with disease progression. See [here](https://archive.ics.uci.edu/ml/datasets/Parkinsons+Telemonitoring) for a description of the data. Note that the UPDRS (Unified Parkinson's Disease Rating Scale) is a standard scale for rating the symptoms of Parkinson's disease across different domains.\n",
    "\n",
    "For this assignment, we have split the dataset into two parts, which you can download here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "yY2quKQnyJn5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File ‘parkinsons_updrs_part1.csv’ already there; not retrieving.\n",
      "\n",
      "--2020-12-01 15:52:13--  https://raw.githubusercontent.com/predictive-clinical-neuroscience/BigDataCourse/main/data/parkinsons_updrs_part2.csv\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.36.133\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.36.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 871968 (852K) [text/plain]\n",
      "Saving to: ‘parkinsons_updrs_part2.csv’\n",
      "\n",
      "parkinsons_updrs_pa 100%[===================>] 851,53K  2,24MB/s    in 0,4s    \n",
      "\n",
      "2020-12-01 15:52:14 (2,24 MB/s) - ‘parkinsons_updrs_part2.csv’ saved [871968/871968]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget -nc https://raw.githubusercontent.com/predictive-clinical-neuroscience/BigDataCourse/main/data/parkinsons_updrs_part1.csv\n",
    "!wget -nc https://raw.githubusercontent.com/predictive-clinical-neuroscience/BigDataCourse/main/data/parkinsons_updrs_part2.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_9dt77USyJn5"
   },
   "source": [
    "### Task 3.0 (1 point, bonus question)\n",
    "Load the data and count the number of rows and columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0WPTDxQ_yJn5"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6lcIMnWiyJn5"
   },
   "source": [
    "### Task 3.1 (1 point)\n",
    "\n",
    "Your first task is to evaluate the basic demographic characteristics, using sns.distplot(). Then answer the following question:\n",
    "\n",
    "* Do you think the dataset is (approximately) representative of the general population of people with Parkinson's disease? Why or why not?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Wl41TH0tyJn5"
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# Plot age\n",
    "\n",
    "# Plot sex\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7bge-LtvyJn5"
   },
   "source": [
    "### Task 3.2 (1 point)\n",
    "\n",
    "Your next task is to fit a GLM to predict motor symptom severity ('motor_UPDRS') on the basis of the 16 biomedical voice measurements using only the first part of the Parkinson dataset. Don't forget that the symptom severity does not have a zero mean. Print out the estimated regression coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S_G6z79XyJn5"
   },
   "outputs": [],
   "source": [
    "# Select 'motor_UPDRS' from dataset\n",
    "y1 = \n",
    "\n",
    "# Select relevant columns\n",
    "cols = \n",
    "\n",
    "# Make the design matrix\n",
    "M1 = \n",
    "print(M1)\n",
    "\n",
    "# Calculate beta\n",
    "beta1 = \n",
    "print(beta1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HmXw4EEryJn5"
   },
   "source": [
    "### Task 3.3 (1 point)\n",
    "\n",
    "Now, evaluate how accurately this model can predict the true symptom scores. To do this compute the correlation between the true and predicted symptom scores as well as the explained variance score. Print these values. \n",
    "\n",
    "Hint: the explained variance can be computed as 1-var(y-yhat)/var(y) where y and yhat are the true and predicted labels respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "thmZRw6tyJn5"
   },
   "outputs": [],
   "source": [
    "# Calculate your predicted scores\n",
    "yhat1 = \n",
    "\n",
    "# Make a scatter plot (optional)\n",
    "\n",
    "# use np.corrcoef()\n",
    "corr = \n",
    "ev = \n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VTGhZxvdyJn5"
   },
   "source": [
    "### Task 3.4 (1 point)\n",
    "\n",
    "Now compute the predictions on the second dataset using the coefficients estimated on the first dataset. Compute and print the correlation and explained variance as above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ILZJhEdKyJn5"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W-YtJY6OyJn5"
   },
   "source": [
    "### Task 3.5 (2 points)\n",
    "\n",
    "Now, we are going to interpret these results. Please answer the following questions:\n",
    "\n",
    "1. Can you see evidence for an association between symptom scores and the voice measurements? Is this a strong association? \n",
    "2. Can you see evidence for overfitting occurring? why or why not? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nhsjbg2xyJn5"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5hTu6r88yJn5"
   },
   "source": [
    "### Task 3.6 (1 point)\n",
    "\n",
    "Now write a small piece of code to compute the accuracy the other way around (i.e. estimating GLM coefficients using the second dataset, then making predictions on the first dataset). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "awMilUgUyJn5"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SFZl5AejyJn5"
   },
   "source": [
    "### Task 3.7 (1 point)\n",
    "\n",
    "Now compare these with the results you have obtained above. Are they the same? If not, why do you think they are different?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uTw7bOQDyJn5"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Assignment1.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
